#!/usr/bin/env python3
"""
æ™ºèƒ½å¯¼å…¥ä¿®å¤è„šæœ¬
ä¿®å¤æœªå®šä¹‰çš„åç§°ã€é‡å¤å¯¼å…¥ã€ç¼ºå¤±å¯¼å…¥ç­‰é—®é¢˜
"""

import os
import re
import ast
import subprocess
from pathlib import Path
from typing import Dict, List, Set, Tuple

# å¸¸è§çš„å¯¼å…¥æ˜ å°„
IMPORT_MAPPINGS = {
    # åŸºç¡€ç±»å‹
    'Dict': 'from typing import Dict',
    'List': 'from typing import List', 
    'Optional': 'from typing import Optional',
    'Any': 'from typing import Any',
    'Union': 'from typing import Union',
    'Tuple': 'from typing import Tuple',
    'Set': 'from typing import Set',
    'Callable': 'from typing import Callable',
    
    # OWL/CAMELç›¸å…³
    'BaseAgent': 'from camel.agents import BaseAgent',
    'ChatAgent': 'from camel.agents import ChatAgent', 
    'BaseMessage': 'from camel.messages import BaseMessage',
    'RolePlaying': 'from camel.societies import RolePlaying',
    
    # é¡¹ç›®å†…éƒ¨æ¨¡å—
    'SystemConfig': 'from ..core.config import SystemConfig',
    'LLMConfig': 'from ..core.config import LLMConfig',
    'LLMProvider': 'from ..utils.enums import LLMProvider',
    'AgentStatus': 'from ..utils.enums import AgentStatus',
    'DocumentFormat': 'from ..utils.enums import DocumentFormat',
    'ProcessingStatus': 'from ..utils.enums import ProcessingStatus',
    
    # å¼‚å¸¸ç±»
    'RequirementsAnalysisError': 'from ..core.exceptions import RequirementsAnalysisError',
    'LLMServiceError': 'from ..core.exceptions import LLMServiceError',
    'ConfigurationError': 'from ..core.exceptions import ConfigurationError',
    'ValidationError': 'from ..core.exceptions import ValidationError',
    
    # æœåŠ¡å’Œç®¡ç†å™¨
    'LLMManager': 'from ..services.llm_manager import LLMManager',
    'get_llm_manager': 'from ..services.llm_manager import get_llm_manager',
    
    # å·¥å…·å’Œå®ç”¨ç¨‹åº
    'extract_json_from_text': 'from ..utils.json_utils import extract_json_from_text',
    'format_json_output': 'from ..utils.json_utils import format_json_output',
    'load_template': 'from ..utils.template_manager import load_template',
    'TemplateManager': 'from ..utils.template_manager import TemplateManager',
    
    # åè°ƒå™¨
    'coordinator': 'from ..core.coordinator import get_coordinator',
    'RequirementsCoordinator': 'from ..core.coordinator import RequirementsCoordinator',
    'get_coordinator': 'from ..core.coordinator import get_coordinator',
}

def analyze_file_imports(filepath: str) -> Tuple[Set[str], Set[str], Set[str]]:
    """åˆ†ææ–‡ä»¶çš„å¯¼å…¥æƒ…å†µ"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # è§£æAST
        try:
            tree = ast.parse(content)
        except SyntaxError as e:
            print(f"  âš ï¸ è¯­æ³•é”™è¯¯ {filepath}: {e}")
            return set(), set(), set()
        
        imported_names = set()
        used_names = set()
        defined_names = set()
        
        # æ”¶é›†å¯¼å…¥çš„åç§°
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    name = alias.asname if alias.asname else alias.name
                    imported_names.add(name)
            elif isinstance(node, ast.ImportFrom):
                if node.names:
                    for alias in node.names:
                        if alias.name != '*':
                            name = alias.asname if alias.asname else alias.name
                            imported_names.add(name)
            elif isinstance(node, ast.Name):
                if isinstance(node.ctx, ast.Load):
                    used_names.add(node.id)
                elif isinstance(node.ctx, ast.Store):
                    defined_names.add(node.id)
            elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
                defined_names.add(node.name)
        
        return imported_names, used_names, defined_names
        
    except Exception as e:
        print(f"  âš ï¸ åˆ†ææ–‡ä»¶å¤±è´¥ {filepath}: {e}")
        return set(), set(), set()

def find_missing_imports(filepath: str) -> List[str]:
    """æŸ¥æ‰¾ç¼ºå¤±çš„å¯¼å…¥"""
    imported_names, used_names, defined_names = analyze_file_imports(filepath)
    
    # æ‰¾åˆ°ä½¿ç”¨ä½†æœªå¯¼å…¥ä¸”æœªå®šä¹‰çš„åç§°
    missing_names = used_names - imported_names - defined_names
    
    # è¿‡æ»¤æ‰å†…ç½®åç§°
    builtin_names = set(dir(__builtins__)) if isinstance(__builtins__, dict) else set(dir(__builtins__))
    missing_names = missing_names - builtin_names
    
    # è¿‡æ»¤æ‰ä¸€äº›å¸¸è§çš„å±€éƒ¨å˜é‡
    common_vars = {'self', 'cls', 'args', 'kwargs', 'e', 'i', 'j', 'k', 'v', 'key', 'value', 'item', 'line', 'result'}
    missing_names = missing_names - common_vars
    
    missing_imports = []
    for name in missing_names:
        if name in IMPORT_MAPPINGS:
            missing_imports.append(IMPORT_MAPPINGS[name])
    
    return missing_imports

def add_missing_imports(filepath: str, missing_imports: List[str]) -> bool:
    """æ·»åŠ ç¼ºå¤±çš„å¯¼å…¥"""
    if not missing_imports:
        return False
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # æ‰¾åˆ°å¯¼å…¥åŒºåŸŸçš„ç»“æŸä½ç½®
        import_end_line = 0
        in_docstring = False
        docstring_quotes = None
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            
            # å¤„ç†æ¨¡å—çº§æ–‡æ¡£å­—ç¬¦ä¸²
            if i < 5 and (stripped.startswith('"""') or stripped.startswith("'''")):
                if not in_docstring:
                    in_docstring = True
                    docstring_quotes = stripped[:3]
                    if len(stripped) > 3 and stripped.endswith(docstring_quotes):
                        in_docstring = False
                elif stripped.endswith(docstring_quotes):
                    in_docstring = False
                continue
            
            if in_docstring:
                continue
            
            # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
            if stripped.startswith('#') or not stripped:
                continue
            
            # å¦‚æœæ˜¯å¯¼å…¥è¯­å¥ï¼Œæ›´æ–°ç»“æŸä½ç½®
            if stripped.startswith(('import ', 'from ')):
                import_end_line = i + 1
            elif stripped and not stripped.startswith(('import ', 'from ')):
                # é‡åˆ°éå¯¼å…¥è¯­å¥ï¼Œåœæ­¢æœç´¢
                break
        
        # åœ¨å¯¼å…¥åŒºåŸŸæœ«å°¾æ·»åŠ ç¼ºå¤±çš„å¯¼å…¥
        new_lines = lines[:import_end_line]
        
        # æ·»åŠ ç¼ºå¤±çš„å¯¼å…¥
        for import_stmt in missing_imports:
            new_lines.append(import_stmt + '\n')
        
        # å¦‚æœæ·»åŠ äº†å¯¼å…¥ï¼Œç¡®ä¿æœ‰ç©ºè¡Œåˆ†éš”
        if missing_imports and import_end_line < len(lines):
            if lines[import_end_line].strip():  # å¦‚æœä¸‹ä¸€è¡Œä¸æ˜¯ç©ºè¡Œ
                new_lines.append('\n')
        
        new_lines.extend(lines[import_end_line:])
        
        # å†™å›æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.writelines(new_lines)
        
        print(f"  âœ… æ·»åŠ äº† {len(missing_imports)} ä¸ªå¯¼å…¥")
        return True
        
    except Exception as e:
        print(f"  âš ï¸ æ·»åŠ å¯¼å…¥å¤±è´¥: {e}")
        return False

def fix_undefined_names(filepath: str) -> bool:
    """ä¿®å¤æœªå®šä¹‰çš„åç§°"""
    print(f"  ä¿®å¤æœªå®šä¹‰åç§°: {filepath}")
    
    # ç‰¹æ®Šå¤„ç†æŸäº›æ–‡ä»¶
    if 'coordinator.py' in filepath:
        return fix_coordinator_issues(filepath)
    
    missing_imports = find_missing_imports(filepath)
    if missing_imports:
        print(f"    å‘ç°ç¼ºå¤±å¯¼å…¥: {missing_imports}")
        return add_missing_imports(filepath, missing_imports)
    
    return False

def fix_coordinator_issues(filepath: str) -> bool:
    """ä¿®å¤coordinatoræ–‡ä»¶çš„ç‰¹æ®Šé—®é¢˜"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ·»åŠ coordinatorå…¨å±€å˜é‡çš„å®šä¹‰
        if 'coordinator' in content and 'global coordinator' not in content:
            # åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å…¨å±€å˜é‡å£°æ˜
            lines = content.split('\n')
            
            # æ‰¾åˆ°åˆé€‚çš„ä½ç½®æ’å…¥å…¨å±€å˜é‡å®šä¹‰
            insert_pos = 0
            for i, line in enumerate(lines):
                if line.strip().startswith('class ') or line.strip().startswith('def '):
                    insert_pos = i
                    break
            
            if insert_pos > 0:
                lines.insert(insert_pos, '')
                lines.insert(insert_pos + 1, '# å…¨å±€åè°ƒå™¨å®ä¾‹')
                lines.insert(insert_pos + 2, '_coordinator_instance = None')
                lines.insert(insert_pos + 3, '')
                lines.insert(insert_pos + 4, 'def get_coordinator():')
                lines.insert(insert_pos + 5, '    """è·å–å…¨å±€åè°ƒå™¨å®ä¾‹"""')
                lines.insert(insert_pos + 6, '    global _coordinator_instance')
                lines.insert(insert_pos + 7, '    if _coordinator_instance is None:')
                lines.insert(insert_pos + 8, '        from .config import SystemConfig')
                lines.insert(insert_pos + 9, '        config = SystemConfig()')
                lines.insert(insert_pos + 10, '        _coordinator_instance = RequirementsCoordinator(config)')
                lines.insert(insert_pos + 11, '    return _coordinator_instance')
                lines.insert(insert_pos + 12, '')
                
                # æ›¿æ¢æ‰€æœ‰ä½¿ç”¨coordinatorçš„åœ°æ–¹
                content = '\n'.join(lines)
                content = re.sub(r'\bcoordinator\b', 'get_coordinator()', content)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                return True
    
    except Exception as e:
        print(f"    âš ï¸ ä¿®å¤coordinatorå¤±è´¥: {e}")
    
    return False

def remove_duplicate_imports(filepath: str) -> bool:
    """ç§»é™¤é‡å¤çš„å¯¼å…¥"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        seen_imports = set()
        new_lines = []
        modified = False
        
        for line in lines:
            stripped = line.strip()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¯¼å…¥è¯­å¥
            if stripped.startswith(('import ', 'from ')):
                if stripped in seen_imports:
                    # è·³è¿‡é‡å¤çš„å¯¼å…¥
                    modified = True
                    continue
                else:
                    seen_imports.add(stripped)
            
            new_lines.append(line)
        
        if modified:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.writelines(new_lines)
            print(f"  âœ… ç§»é™¤äº†é‡å¤å¯¼å…¥")
            return True
            
    except Exception as e:
        print(f"  âš ï¸ ç§»é™¤é‡å¤å¯¼å…¥å¤±è´¥: {e}")
    
    return False

def fix_redefinition_issues(filepath: str) -> bool:
    """ä¿®å¤é‡å¤å®šä¹‰é—®é¢˜"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        modified = False
        
        # ä¿®å¤typeré‡å¤å¯¼å…¥
        if 'cli/app.py' in filepath:
            # ç§»é™¤é‡å¤çš„typerå¯¼å…¥
            lines = content.split('\n')
            new_lines = []
            typer_imported = False
            
            for line in lines:
                if 'import typer' in line or 'from typer import' in line:
                    if not typer_imported:
                        new_lines.append(line)
                        typer_imported = True
                    else:
                        modified = True
                        continue
                else:
                    new_lines.append(line)
            
            if modified:
                content = '\n'.join(new_lines)
        
        # ä¿®å¤å…¶ä»–é‡å¤å®šä¹‰
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šç‰¹å®šçš„ä¿®å¤é€»è¾‘
        
        if modified:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            return True
            
    except Exception as e:
        print(f"  âš ï¸ ä¿®å¤é‡å¤å®šä¹‰å¤±è´¥: {e}")
    
    return False

def fix_syntax_errors(filepath: str) -> bool:
    """ä¿®å¤è¯­æ³•é”™è¯¯"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¯­æ³•é”™è¯¯
        try:
            ast.parse(content)
            return False  # æ²¡æœ‰è¯­æ³•é”™è¯¯
        except IndentationError as e:
            print(f"  ä¿®å¤ç¼©è¿›é”™è¯¯: {e}")
            # å°è¯•ä¿®å¤ç¼©è¿›é—®é¢˜
            lines = content.split('\n')
            fixed_lines = []
            
            for line in lines:
                # ç®€å•çš„ç¼©è¿›ä¿®å¤ï¼šå°†åˆ¶è¡¨ç¬¦è½¬æ¢ä¸ºç©ºæ ¼
                fixed_line = line.expandtabs(4)
                fixed_lines.append(fixed_line)
            
            fixed_content = '\n'.join(fixed_lines)
            
            # éªŒè¯ä¿®å¤ç»“æœ
            try:
                ast.parse(fixed_content)
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(fixed_content)
                print(f"  âœ… ä¿®å¤äº†ç¼©è¿›é”™è¯¯")
                return True
            except:
                pass
        
        except SyntaxError as e:
            print(f"  âš ï¸ è¯­æ³•é”™è¯¯æ— æ³•è‡ªåŠ¨ä¿®å¤: {e}")
    
    except Exception as e:
        print(f"  âš ï¸ æ£€æŸ¥è¯­æ³•é”™è¯¯å¤±è´¥: {e}")
    
    return False

def fix_file_imports(filepath: str) -> bool:
    """ä¿®å¤å•ä¸ªæ–‡ä»¶çš„å¯¼å…¥é—®é¢˜"""
    print(f"ä¿®å¤æ–‡ä»¶: {filepath}")
    
    modified = False
    
    # 1. ä¿®å¤è¯­æ³•é”™è¯¯
    if fix_syntax_errors(filepath):
        modified = True
    
    # 2. ç§»é™¤é‡å¤å¯¼å…¥
    if remove_duplicate_imports(filepath):
        modified = True
    
    # 3. ä¿®å¤é‡å¤å®šä¹‰
    if fix_redefinition_issues(filepath):
        modified = True
    
    # 4. ä¿®å¤æœªå®šä¹‰çš„åç§°
    if fix_undefined_names(filepath):
        modified = True
    
    return modified

def create_missing_enums():
    """åˆ›å»ºç¼ºå¤±çš„æšä¸¾å®šä¹‰"""
    print("åˆ›å»ºç¼ºå¤±çš„æšä¸¾å®šä¹‰...")
    
    enums_file = "src/owl_requirements/utils/enums.py"
    
    try:
        with open(enums_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘AgentStatus
        if 'class AgentStatus' not in content:
            content += '''

class AgentStatus(Enum):
    """æ™ºèƒ½ä½“çŠ¶æ€"""
    IDLE = "idle"
    PROCESSING = "processing"
    COMPLETED = "completed"
    ERROR = "error"
    WAITING = "waiting"
'''
        
        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘ProcessingStatus
        if 'class ProcessingStatus' not in content:
            content += '''

class ProcessingStatus(Enum):
    """å¤„ç†çŠ¶æ€"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
'''
        
        with open(enums_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print("  âœ… æšä¸¾å®šä¹‰å·²æ›´æ–°")
        
    except Exception as e:
        print(f"  âš ï¸ åˆ›å»ºæšä¸¾å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ä¿®å¤å¯¼å…¥å’Œå®šä¹‰é—®é¢˜...")
    
    # 1. åˆ›å»ºç¼ºå¤±çš„æšä¸¾å®šä¹‰
    create_missing_enums()
    
    # 2. è·å–æ‰€æœ‰Pythonæ–‡ä»¶
    python_files = []
    for root, dirs, files in os.walk("src"):
        dirs[:] = [d for d in dirs if d != "__pycache__"]
        
        for file in files:
            if file.endswith('.py'):
                python_files.append(os.path.join(root, file))
    
    print(f"æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")
    
    # 3. ä¿®å¤æ¯ä¸ªæ–‡ä»¶
    success_count = 0
    for filepath in python_files:
        if fix_file_imports(filepath):
            success_count += 1
    
    print(f"æˆåŠŸä¿®å¤ {success_count} ä¸ªæ–‡ä»¶")
    
    # 4. å†æ¬¡æ£€æŸ¥é”™è¯¯
    print("\næ£€æŸ¥ä¿®å¤ç»“æœ...")
    try:
        result = subprocess.run(
            ["python", "-m", "flake8", "src/", "--count", "--statistics", "--max-line-length=88"],
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            print("âœ… æ‰€æœ‰å¯¼å…¥é”™è¯¯å·²ä¿®å¤ï¼")
        else:
            error_lines = [line for line in result.stdout.split('\n') if ':' in line and 'src/' in line]
            print(f"ğŸ“Š å‰©ä½™é”™è¯¯æ•°é‡: {len(error_lines)}")
            
            # æ˜¾ç¤ºä¸»è¦é”™è¯¯ç±»å‹
            error_types = {}
            for line in error_lines:
                if ' F' in line:  # Få¼€å¤´çš„é”™è¯¯
                    match = re.search(r' (F\d+) ', line)
                    if match:
                        error_code = match.group(1)
                        error_types[error_code] = error_types.get(error_code, 0) + 1
            
            if error_types:
                print("ä¸»è¦é”™è¯¯ç±»å‹:")
                for error_code, count in sorted(error_types.items()):
                    print(f"  {error_code}: {count} ä¸ª")
    
    except Exception as e:
        print(f"æ£€æŸ¥å¤±è´¥: {e}")
    
    print("ğŸ‰ å¯¼å…¥ä¿®å¤å®Œæˆï¼")

if __name__ == "__main__":
    main() 