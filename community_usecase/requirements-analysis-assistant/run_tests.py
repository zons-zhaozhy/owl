#!/usr/bin/env python3
"""
æµ‹è¯•è¿è¡Œè„šæœ¬
æä¾›å¤šç§æµ‹è¯•æ‰§è¡Œé€‰é¡¹å’ŒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½
"""
import os
import sys
import subprocess
import argparse
import time
from pathlib import Path
from typing import List, Optional

def run_command(cmd: List[str], cwd: Optional[Path] = None) -> int:
    """è¿è¡Œå‘½ä»¤å¹¶è¿”å›é€€å‡ºç """
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    try:
        result = subprocess.run(
            cmd,
            cwd=cwd,
            capture_output=False,
            text=True
        )
        return result.returncode
    except Exception as e:
        print(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
        return 1

def run_unit_tests(verbose: bool = False) -> int:
    """è¿è¡Œå•å…ƒæµ‹è¯•"""
    print("ğŸ§ª è¿è¡Œå•å…ƒæµ‹è¯•...")
    
    cmd = ["python", "-m", "pytest", "tests/", "-m", "unit"]
    
    if verbose:
        cmd.append("-v")
    
    cmd.extend([
        "--tb=short",
        "--color=yes",
        "--durations=10"
    ])
    
    return run_command(cmd)

def run_integration_tests(verbose: bool = False) -> int:
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    print("ğŸ”— è¿è¡Œé›†æˆæµ‹è¯•...")
    
    cmd = ["python", "-m", "pytest", "tests/", "-m", "integration"]
    
    if verbose:
        cmd.append("-v")
    
    cmd.extend([
        "--tb=short",
        "--color=yes",
        "--durations=10"
    ])
    
    return run_command(cmd)

def run_performance_tests(verbose: bool = False) -> int:
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("âš¡ è¿è¡Œæ€§èƒ½æµ‹è¯•...")
    
    cmd = ["python", "-m", "pytest", "tests/", "-m", "performance"]
    
    if verbose:
        cmd.append("-v")
    
    cmd.extend([
        "--tb=short",
        "--color=yes",
        "--durations=0"
    ])
    
    return run_command(cmd)

def run_all_tests(verbose: bool = False, coverage: bool = False) -> int:
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ è¿è¡Œæ‰€æœ‰æµ‹è¯•...")
    
    cmd = ["python", "-m", "pytest", "tests/"]
    
    if verbose:
        cmd.append("-v")
    
    if coverage:
        cmd.extend([
            "--cov=src",
            "--cov-report=html",
            "--cov-report=term-missing",
            "--cov-fail-under=80"
        ])
    
    cmd.extend([
        "--tb=short",
        "--color=yes",
        "--durations=10"
    ])
    
    return run_command(cmd)

def run_specific_test(test_path: str, verbose: bool = False) -> int:
    """è¿è¡Œç‰¹å®šæµ‹è¯•"""
    print(f"ğŸ¯ è¿è¡Œç‰¹å®šæµ‹è¯•: {test_path}")
    
    cmd = ["python", "-m", "pytest", test_path]
    
    if verbose:
        cmd.append("-v")
    
    cmd.extend([
        "--tb=short",
        "--color=yes"
    ])
    
    return run_command(cmd)

def run_fast_tests(verbose: bool = False) -> int:
    """è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆæ’é™¤æ…¢é€Ÿæµ‹è¯•ï¼‰"""
    print("âš¡ è¿è¡Œå¿«é€Ÿæµ‹è¯•...")
    
    cmd = ["python", "-m", "pytest", "tests/", "-m", "not slow"]
    
    if verbose:
        cmd.append("-v")
    
    cmd.extend([
        "--tb=short",
        "--color=yes",
        "--durations=10"
    ])
    
    return run_command(cmd)

def run_external_tests(verbose: bool = False) -> int:
    """è¿è¡Œéœ€è¦å¤–éƒ¨æœåŠ¡çš„æµ‹è¯•"""
    print("ğŸŒ è¿è¡Œå¤–éƒ¨æœåŠ¡æµ‹è¯•...")
    
    cmd = ["python", "-m", "pytest", "tests/", "-m", "external"]
    
    if verbose:
        cmd.append("-v")
    
    cmd.extend([
        "--tb=short",
        "--color=yes",
        "--durations=10"
    ])
    
    return run_command(cmd)

def run_parallel_tests(workers: int = 4, verbose: bool = False) -> int:
    """å¹¶è¡Œè¿è¡Œæµ‹è¯•"""
    print(f"ğŸ”„ å¹¶è¡Œè¿è¡Œæµ‹è¯• (workers: {workers})...")
    
    cmd = ["python", "-m", "pytest", "tests/", "-n", str(workers)]
    
    if verbose:
        cmd.append("-v")
    
    cmd.extend([
        "--tb=short",
        "--color=yes",
        "--durations=10"
    ])
    
    return run_command(cmd)

def generate_test_report(output_dir: str = "test_reports") -> int:
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("ğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
    
    # åˆ›å»ºæŠ¥å‘Šç›®å½•
    report_dir = Path(output_dir)
    report_dir.mkdir(exist_ok=True)
    
    # ç”ŸæˆHTMLæŠ¥å‘Š
    cmd = [
        "python", "-m", "pytest", "tests/",
        "--html", str(report_dir / "report.html"),
        "--self-contained-html",
        "--cov=src",
        "--cov-report=html:" + str(report_dir / "coverage"),
        "--cov-report=xml:" + str(report_dir / "coverage.xml"),
        "--junit-xml=" + str(report_dir / "junit.xml")
    ]
    
    return run_command(cmd)

def check_test_dependencies() -> bool:
    """æ£€æŸ¥æµ‹è¯•ä¾èµ–"""
    print("ğŸ” æ£€æŸ¥æµ‹è¯•ä¾èµ–...")
    
    required_packages = [
        "pytest",
        "pytest-cov",
        "pytest-html",
        "pytest-xdist",
        "pytest-mock"
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            if package == "pytest-xdist":
                __import__("xdist")
            elif package == "pytest-html":
                __import__("pytest_html")
            elif package == "pytest-mock":
                __import__("pytest_mock")
            elif package == "pytest-cov":
                __import__("pytest_cov")
            else:
                __import__(package.replace("-", "_"))
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: pip install " + " ".join(missing_packages))
        return False
    
    print("âœ… æ‰€æœ‰æµ‹è¯•ä¾èµ–å·²å®‰è£…")
    return True

def clean_test_artifacts():
    """æ¸…ç†æµ‹è¯•äº§ç‰©"""
    print("ğŸ§¹ æ¸…ç†æµ‹è¯•äº§ç‰©...")
    
    patterns = [
        ".pytest_cache",
        "__pycache__",
        "*.pyc",
        ".coverage",
        "htmlcov",
        "test_reports",
        ".tox"
    ]
    
    for pattern in patterns:
        if pattern.startswith("."):
            # åˆ é™¤ç›®å½•
            for path in Path(".").rglob(pattern):
                if path.is_dir():
                    import shutil
                    shutil.rmtree(path, ignore_errors=True)
                    print(f"åˆ é™¤ç›®å½•: {path}")
        else:
            # åˆ é™¤æ–‡ä»¶
            for path in Path(".").rglob(pattern):
                if path.is_file():
                    path.unlink()
                    print(f"åˆ é™¤æ–‡ä»¶: {path}")

def setup_test_environment():
    """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
    print("âš™ï¸ è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["OWL_ENV"] = "test"
    os.environ["OWL_LOG_LEVEL"] = "DEBUG"
    os.environ["PYTHONPATH"] = str(Path.cwd())
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    test_dirs = ["logs", "cache", "temp"]
    for dir_name in test_dirs:
        Path(dir_name).mkdir(exist_ok=True)
    
    print("âœ… æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="éœ€æ±‚åˆ†æåŠ©æ‰‹æµ‹è¯•è¿è¡Œå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python run_tests.py --all                    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
  python run_tests.py --unit --verbose         # è¿è¡Œå•å…ƒæµ‹è¯•ï¼ˆè¯¦ç»†è¾“å‡ºï¼‰
  python run_tests.py --integration            # è¿è¡Œé›†æˆæµ‹è¯•
  python run_tests.py --performance            # è¿è¡Œæ€§èƒ½æµ‹è¯•
  python run_tests.py --test tests/test_cli.py # è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
  python run_tests.py --fast --parallel 8     # å¹¶è¡Œè¿è¡Œå¿«é€Ÿæµ‹è¯•
  python run_tests.py --report                 # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
  python run_tests.py --clean                  # æ¸…ç†æµ‹è¯•äº§ç‰©
        """
    )
    
    # æµ‹è¯•ç±»å‹é€‰é¡¹
    test_group = parser.add_mutually_exclusive_group()
    test_group.add_argument("--all", action="store_true", help="è¿è¡Œæ‰€æœ‰æµ‹è¯•")
    test_group.add_argument("--unit", action="store_true", help="è¿è¡Œå•å…ƒæµ‹è¯•")
    test_group.add_argument("--integration", action="store_true", help="è¿è¡Œé›†æˆæµ‹è¯•")
    test_group.add_argument("--performance", action="store_true", help="è¿è¡Œæ€§èƒ½æµ‹è¯•")
    test_group.add_argument("--fast", action="store_true", help="è¿è¡Œå¿«é€Ÿæµ‹è¯•")
    test_group.add_argument("--external", action="store_true", help="è¿è¡Œå¤–éƒ¨æœåŠ¡æµ‹è¯•")
    test_group.add_argument("--test", type=str, help="è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶")
    
    # è¿è¡Œé€‰é¡¹
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")
    parser.add_argument("--coverage", "-c", action="store_true", help="ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š")
    parser.add_argument("--parallel", "-p", type=int, default=4, help="å¹¶è¡Œè¿è¡Œæµ‹è¯•çš„è¿›ç¨‹æ•°")
    
    # å·¥å…·é€‰é¡¹
    parser.add_argument("--report", action="store_true", help="ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š")
    parser.add_argument("--clean", action="store_true", help="æ¸…ç†æµ‹è¯•äº§ç‰©")
    parser.add_argument("--check-deps", action="store_true", help="æ£€æŸ¥æµ‹è¯•ä¾èµ–")
    parser.add_argument("--setup", action="store_true", help="è®¾ç½®æµ‹è¯•ç¯å¢ƒ")
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•é€‰é¡¹ï¼Œæ˜¾ç¤ºå¸®åŠ©
    if len(sys.argv) == 1:
        parser.print_help()
        return 0
    
    # å¤„ç†å·¥å…·é€‰é¡¹
    if args.clean:
        clean_test_artifacts()
        return 0
    
    if args.check_deps:
        return 0 if check_test_dependencies() else 1
    
    if args.setup:
        setup_test_environment()
        return 0
    
    if args.report:
        return generate_test_report()
    
    # æ£€æŸ¥ä¾èµ–
    if not check_test_dependencies():
        return 1
    
    # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
    setup_test_environment()
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # è¿è¡Œæµ‹è¯•
    exit_code = 0
    
    try:
        if args.all:
            exit_code = run_all_tests(args.verbose, args.coverage)
        elif args.unit:
            exit_code = run_unit_tests(args.verbose)
        elif args.integration:
            exit_code = run_integration_tests(args.verbose)
        elif args.performance:
            exit_code = run_performance_tests(args.verbose)
        elif args.fast:
            if args.parallel > 1:
                exit_code = run_parallel_tests(args.parallel, args.verbose)
            else:
                exit_code = run_fast_tests(args.verbose)
        elif args.external:
            exit_code = run_external_tests(args.verbose)
        elif args.test:
            exit_code = run_specific_test(args.test, args.verbose)
        else:
            # é»˜è®¤è¿è¡Œå¿«é€Ÿæµ‹è¯•
            exit_code = run_fast_tests(args.verbose)
            
    except KeyboardInterrupt:
        print("\nâŒ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        exit_code = 130
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
        exit_code = 1
    
    # è®¡ç®—è¿è¡Œæ—¶é—´
    end_time = time.time()
    duration = end_time - start_time
    
    # è¾“å‡ºç»“æœ
    if exit_code == 0:
        print(f"\nâœ… æµ‹è¯•å®Œæˆ (è€—æ—¶: {duration:.2f}ç§’)")
    else:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥ (è€—æ—¶: {duration:.2f}ç§’)")
    
    return exit_code

if __name__ == "__main__":
    sys.exit(main()) 