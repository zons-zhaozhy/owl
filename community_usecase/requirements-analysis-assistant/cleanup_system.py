#!/usr/bin/env python3
"""
ç³»ç»Ÿæ¸…ç†è„šæœ¬ - æ¸…ç†é‡å¤çš„å®ç°å’Œæ¨¡å—
"""

import os
import shutil
import json
from pathlib import Path
from typing import Dict, List, Set, Tuple
import difflib

def find_duplicate_files() -> Dict[str, List[str]]:
    """æŸ¥æ‰¾é‡å¤çš„æ–‡ä»¶"""
    print("ğŸ” æŸ¥æ‰¾é‡å¤æ–‡ä»¶...")
    
    file_contents = {}
    duplicates = {}
    
    # æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶
    for root, dirs, files in os.walk("src"):
        # è·³è¿‡__pycache__ç›®å½•
        dirs[:] = [d for d in dirs if d != "__pycache__"]
        
        for file in files:
            if file.endswith('.py'):
                filepath = os.path.join(root, file)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        if content:
                            if content in file_contents:
                                if content not in duplicates:
                                    duplicates[content] = [file_contents[content]]
                                duplicates[content].append(filepath)
                            else:
                                file_contents[content] = filepath
                except Exception as e:
                    print(f"  âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
    
    return duplicates

def find_similar_files(threshold: float = 0.8) -> List[Tuple[str, str, float]]:
    """æŸ¥æ‰¾ç›¸ä¼¼çš„æ–‡ä»¶"""
    print("ğŸ” æŸ¥æ‰¾ç›¸ä¼¼æ–‡ä»¶...")
    
    files_content = {}
    
    # æ”¶é›†æ‰€æœ‰Pythonæ–‡ä»¶å†…å®¹
    for root, dirs, files in os.walk("src"):
        dirs[:] = [d for d in dirs if d != "__pycache__"]
        
        for file in files:
            if file.endswith('.py'):
                filepath = os.path.join(root, file)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        if content and len(content) > 100:  # å¿½ç•¥å¤ªçŸ­çš„æ–‡ä»¶
                            files_content[filepath] = content
                except Exception:
                    continue
    
    similar_files = []
    file_paths = list(files_content.keys())
    
    for i, file1 in enumerate(file_paths):
        for file2 in file_paths[i+1:]:
            content1 = files_content[file1]
            content2 = files_content[file2]
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = difflib.SequenceMatcher(None, content1, content2).ratio()
            
            if similarity >= threshold:
                similar_files.append((file1, file2, similarity))
    
    return similar_files

def analyze_llm_implementations():
    """åˆ†æLLMç›¸å…³çš„å®ç°"""
    print("ğŸ” åˆ†æLLMå®ç°...")
    
    llm_files = []
    
    # æŸ¥æ‰¾æ‰€æœ‰LLMç›¸å…³æ–‡ä»¶
    for root, dirs, files in os.walk("src"):
        dirs[:] = [d for d in dirs if d != "__pycache__"]
        
        for file in files:
            if 'llm' in file.lower() and file.endswith('.py'):
                filepath = os.path.join(root, file)
                llm_files.append(filepath)
    
    print(f"  ğŸ“ æ‰¾åˆ°LLMç›¸å…³æ–‡ä»¶: {len(llm_files)}")
    for file in llm_files:
        print(f"    - {file}")
    
    return llm_files

def find_duplicate_templates():
    """æŸ¥æ‰¾é‡å¤çš„æ¨¡æ¿æ–‡ä»¶"""
    print("ğŸ” æŸ¥æ‰¾é‡å¤æ¨¡æ¿...")
    
    template_files = {}
    duplicates = []
    
    # æŸ¥æ‰¾æ‰€æœ‰æ¨¡æ¿ç›®å½•
    template_dirs = []
    for root, dirs, files in os.walk("."):
        if "template" in root.lower():
            template_dirs.append(root)
    
    print(f"  ğŸ“ æ‰¾åˆ°æ¨¡æ¿ç›®å½•: {len(template_dirs)}")
    for dir_path in template_dirs:
        print(f"    - {dir_path}")
        
        # æ£€æŸ¥æ¯ä¸ªæ¨¡æ¿ç›®å½•ä¸­çš„æ–‡ä»¶
        if os.path.exists(dir_path):
            for file in os.listdir(dir_path):
                if file.endswith(('.json', '.txt', '.md')):
                    filepath = os.path.join(dir_path, file)
                    try:
                        with open(filepath, 'r', encoding='utf-8') as f:
                            content = f.read().strip()
                            
                        if file in template_files:
                            # æ£€æŸ¥å†…å®¹æ˜¯å¦ç›¸åŒ
                            if content == template_files[file]['content']:
                                duplicates.append({
                                    'file': file,
                                    'paths': [template_files[file]['path'], filepath],
                                    'content_length': len(content)
                                })
                            else:
                                template_files[file]['similar_paths'] = template_files[file].get('similar_paths', [])
                                template_files[file]['similar_paths'].append(filepath)
                        else:
                            template_files[file] = {
                                'path': filepath,
                                'content': content
                            }
                    except Exception as e:
                        print(f"    âš ï¸ è¯»å–æ¨¡æ¿å¤±è´¥ {filepath}: {e}")
    
    return duplicates, template_dirs

def cleanup_duplicate_templates():
    """æ¸…ç†é‡å¤çš„æ¨¡æ¿"""
    print("\nğŸ§¹ å¼€å§‹æ¸…ç†é‡å¤æ¨¡æ¿...")
    
    duplicates, template_dirs = find_duplicate_templates()
    
    if not duplicates:
        print("âœ… æ²¡æœ‰å‘ç°é‡å¤çš„æ¨¡æ¿æ–‡ä»¶")
        return
    
    print(f"  ğŸ” å‘ç° {len(duplicates)} ä¸ªé‡å¤æ¨¡æ¿:")
    
    for dup in duplicates:
        print(f"    ğŸ“„ {dup['file']} (å†…å®¹é•¿åº¦: {dup['content_length']})")
        for path in dup['paths']:
            print(f"      - {path}")
        
        # ä¿ç•™templates/prompts/ç›®å½•ä¸­çš„ç‰ˆæœ¬ï¼Œåˆ é™¤å…¶ä»–çš„
        keep_path = None
        remove_paths = []
        
        for path in dup['paths']:
            if 'templates/prompts/' in path:
                keep_path = path
            else:
                remove_paths.append(path)
        
        if not keep_path:
            # å¦‚æœæ²¡æœ‰åœ¨templates/prompts/ä¸­çš„ï¼Œä¿ç•™ç¬¬ä¸€ä¸ª
            keep_path = dup['paths'][0]
            remove_paths = dup['paths'][1:]
        
        print(f"      âœ… ä¿ç•™: {keep_path}")
        
        for remove_path in remove_paths:
            try:
                os.remove(remove_path)
                print(f"      ğŸ—‘ï¸ åˆ é™¤: {remove_path}")
            except Exception as e:
                print(f"      âš ï¸ åˆ é™¤å¤±è´¥ {remove_path}: {e}")

def cleanup_web_templates():
    """æ¸…ç†é‡å¤çš„Webæ¨¡æ¿"""
    print("\nğŸ§¹ æ¸…ç†é‡å¤çš„Webæ¨¡æ¿...")
    
    web_template_paths = [
        "src/web/templates/",
        "src/owl_requirements/web/templates/"
    ]
    
    for path in web_template_paths:
        if os.path.exists(path):
            print(f"  ğŸ“ æ‰¾åˆ°Webæ¨¡æ¿ç›®å½•: {path}")
            
            # å¦‚æœä¸æ˜¯ä¸»è¦çš„webæ¨¡æ¿ç›®å½•ï¼Œåˆ é™¤å®ƒ
            if path != "src/owl_requirements/web/templates/":
                try:
                    shutil.rmtree(path)
                    print(f"  ğŸ—‘ï¸ åˆ é™¤é‡å¤ç›®å½•: {path}")
                except Exception as e:
                    print(f"  âš ï¸ åˆ é™¤å¤±è´¥ {path}: {e}")

def cleanup_empty_dirs():
    """æ¸…ç†ç©ºç›®å½•"""
    print("\nğŸ§¹ æ¸…ç†ç©ºç›®å½•...")
    
    def remove_empty_dirs(path):
        """é€’å½’åˆ é™¤ç©ºç›®å½•"""
        if not os.path.isdir(path):
            return
        
        # å…ˆå¤„ç†å­ç›®å½•
        for item in os.listdir(path):
            item_path = os.path.join(path, item)
            if os.path.isdir(item_path):
                remove_empty_dirs(item_path)
        
        # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦ä¸ºç©º
        try:
            if not os.listdir(path) and path != "src":  # ä¸åˆ é™¤srcæ ¹ç›®å½•
                os.rmdir(path)
                print(f"  ğŸ—‘ï¸ åˆ é™¤ç©ºç›®å½•: {path}")
        except OSError:
            pass
    
    remove_empty_dirs("src")

def verify_template_consistency():
    """éªŒè¯æ¨¡æ¿ä¸€è‡´æ€§"""
    print("\nğŸ” éªŒè¯æ¨¡æ¿ä¸€è‡´æ€§...")
    
    required_templates = [
        "requirements_extraction.json",
        "requirements_analysis.json", 
        "quality_checker.json",
        "documentation_generator.json"
    ]
    
    template_dir = "templates/prompts"
    if not os.path.exists(template_dir):
        print(f"  âš ï¸ æ¨¡æ¿ç›®å½•ä¸å­˜åœ¨: {template_dir}")
        return False
    
    missing_templates = []
    for template in required_templates:
        template_path = os.path.join(template_dir, template)
        if not os.path.exists(template_path):
            missing_templates.append(template)
    
    if missing_templates:
        print(f"  âš ï¸ ç¼ºå°‘æ¨¡æ¿: {missing_templates}")
        return False
    else:
        print(f"  âœ… æ‰€æœ‰å¿…éœ€çš„æ¨¡æ¿éƒ½å­˜åœ¨")
        return True

def create_a2a_framework():
    """åˆ›å»ºA2Aé€šä¿¡æ¡†æ¶"""
    print("\nğŸ”§ åˆ›å»ºA2Aé€šä¿¡æ¡†æ¶...")
    
    a2a_file = "src/owl_requirements/core/a2a_communication.py"
    
    if os.path.exists(a2a_file):
        print(f"  âœ… A2Aé€šä¿¡æ–‡ä»¶å·²å­˜åœ¨: {a2a_file}")
        return
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(a2a_file), exist_ok=True)
    
    a2a_content = '''"""
A2A (Agent-to-Agent) é€šä¿¡æ¡†æ¶
åŸºäºOWLæ¡†æ¶çš„æ™ºèƒ½ä½“é—´é€šä¿¡ç³»ç»Ÿ
"""

from enum import Enum
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from camel.messages import BaseMessage
from camel.agents import ChatAgent
import asyncio
import logging

logger = logging.getLogger(__name__)


class A2AMessageType(Enum):
    """A2Aæ¶ˆæ¯ç±»å‹"""
    CLARIFICATION_REQUEST = "clarification_request"
    CLARIFICATION_RESPONSE = "clarification_response"
    QUALITY_FEEDBACK = "quality_feedback"
    COLLABORATION_REQUEST = "collaboration_request"
    COLLABORATION_RESPONSE = "collaboration_response"
    STATUS_UPDATE = "status_update"


@dataclass
class A2AMessage:
    """A2Aæ¶ˆæ¯ç»“æ„"""
    message_type: A2AMessageType
    sender_agent: str
    receiver_agent: str
    content: str
    metadata: Optional[Dict[str, Any]] = None
    conversation_id: Optional[str] = None
    
    def to_base_message(self) -> BaseMessage:
        """è½¬æ¢ä¸ºCAMEL BaseMessage"""
        return BaseMessage(
            role_name=self.sender_agent,
            role_type="assistant",
            meta_dict={
                "message_type": self.message_type.value,
                "receiver": self.receiver_agent,
                "conversation_id": self.conversation_id,
                **(self.metadata or {})
            },
            content=self.content
        )


class RequirementsClarificationWorkflow:
    """éœ€æ±‚æ¾„æ¸…å·¥ä½œæµ"""
    
    def __init__(self):
        self.active_conversations: Dict[str, List[A2AMessage]] = {}
    
    async def start_clarification(
        self, 
        extractor_agent: ChatAgent,
        analyzer_agent: ChatAgent,
        unclear_requirement: str,
        conversation_id: str
    ) -> str:
        """å¼€å§‹éœ€æ±‚æ¾„æ¸…æµç¨‹"""
        
        # åˆ›å»ºæ¾„æ¸…è¯·æ±‚æ¶ˆæ¯
        clarification_msg = A2AMessage(
            message_type=A2AMessageType.CLARIFICATION_REQUEST,
            sender_agent="requirements_extractor",
            receiver_agent="requirements_analyzer", 
            content=f"éœ€è¦æ¾„æ¸…ä»¥ä¸‹éœ€æ±‚: {unclear_requirement}",
            conversation_id=conversation_id
        )
        
        # è®°å½•å¯¹è¯
        if conversation_id not in self.active_conversations:
            self.active_conversations[conversation_id] = []
        self.active_conversations[conversation_id].append(clarification_msg)
        
        # å‘é€ç»™åˆ†ææ™ºèƒ½ä½“
        analyzer_response = await analyzer_agent.step(clarification_msg.to_base_message())
        
        # å¤„ç†å“åº”
        response_msg = A2AMessage(
            message_type=A2AMessageType.CLARIFICATION_RESPONSE,
            sender_agent="requirements_analyzer",
            receiver_agent="requirements_extractor",
            content=analyzer_response.content,
            conversation_id=conversation_id
        )
        
        self.active_conversations[conversation_id].append(response_msg)
        
        return analyzer_response.content


class QualityFeedbackWorkflow:
    """è´¨é‡åé¦ˆå·¥ä½œæµ"""
    
    async def provide_feedback(
        self,
        quality_agent: ChatAgent,
        target_agent: ChatAgent,
        feedback_content: str,
        target_agent_name: str
    ) -> str:
        """æä¾›è´¨é‡åé¦ˆ"""
        
        feedback_msg = A2AMessage(
            message_type=A2AMessageType.QUALITY_FEEDBACK,
            sender_agent="quality_checker",
            receiver_agent=target_agent_name,
            content=feedback_content
        )
        
        # å‘é€åé¦ˆ
        response = await target_agent.step(feedback_msg.to_base_message())
        
        return response.content


class A2ACoordinator:
    """A2Aåè°ƒå™¨"""
    
    def __init__(self):
        self.registered_agents: Dict[str, ChatAgent] = {}
        self.message_queue: List[A2AMessage] = []
        self.clarification_workflow = RequirementsClarificationWorkflow()
        self.feedback_workflow = QualityFeedbackWorkflow()
    
    def register_agent(self, agent_name: str, agent: ChatAgent):
        """æ³¨å†Œæ™ºèƒ½ä½“"""
        self.registered_agents[agent_name] = agent
        logger.info(f"å·²æ³¨å†Œæ™ºèƒ½ä½“: {agent_name}")
    
    async def route_message(self, message: A2AMessage) -> Optional[str]:
        """è·¯ç”±æ¶ˆæ¯"""
        receiver = self.registered_agents.get(message.receiver_agent)
        if not receiver:
            logger.error(f"æœªæ‰¾åˆ°æ¥æ”¶æ™ºèƒ½ä½“: {message.receiver_agent}")
            return None
        
        try:
            response = await receiver.step(message.to_base_message())
            return response.content
        except Exception as e:
            logger.error(f"æ¶ˆæ¯è·¯ç”±å¤±è´¥: {e}")
            return None
    
    async def start_clarification_session(
        self,
        unclear_requirement: str,
        conversation_id: str
    ) -> str:
        """å¼€å§‹æ¾„æ¸…ä¼šè¯"""
        extractor = self.registered_agents.get("requirements_extractor")
        analyzer = self.registered_agents.get("requirements_analyzer")
        
        if not extractor or not analyzer:
            raise ValueError("éœ€æ±‚æå–æˆ–åˆ†ææ™ºèƒ½ä½“æœªæ³¨å†Œ")
        
        return await self.clarification_workflow.start_clarification(
            extractor, analyzer, unclear_requirement, conversation_id
        )


class A2AAgentMixin:
    """A2Aæ™ºèƒ½ä½“æ··å…¥ç±»"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.a2a_coordinator: Optional[A2ACoordinator] = None
    
    def set_a2a_coordinator(self, coordinator: A2ACoordinator):
        """è®¾ç½®A2Aåè°ƒå™¨"""
        self.a2a_coordinator = coordinator
    
    async def send_a2a_message(self, message: A2AMessage) -> Optional[str]:
        """å‘é€A2Aæ¶ˆæ¯"""
        if not self.a2a_coordinator:
            logger.warning("A2Aåè°ƒå™¨æœªè®¾ç½®")
            return None
        
        return await self.a2a_coordinator.route_message(message)
    
    async def request_clarification(
        self, 
        target_agent: str,
        unclear_content: str,
        conversation_id: str
    ) -> Optional[str]:
        """è¯·æ±‚æ¾„æ¸…"""
        message = A2AMessage(
            message_type=A2AMessageType.CLARIFICATION_REQUEST,
            sender_agent=self.__class__.__name__.lower(),
            receiver_agent=target_agent,
            content=unclear_content,
            conversation_id=conversation_id
        )
        
        return await self.send_a2a_message(message)
'''
    
    try:
        with open(a2a_file, 'w', encoding='utf-8') as f:
            f.write(a2a_content)
        print(f"  âœ… åˆ›å»ºA2Aé€šä¿¡æ–‡ä»¶: {a2a_file}")
    except Exception as e:
        print(f"  âš ï¸ åˆ›å»ºA2Aæ–‡ä»¶å¤±è´¥: {e}")

def cleanup_llm_duplicates():
    """æ¸…ç†LLMé‡å¤å®ç°"""
    print("\nğŸ§¹ æ¸…ç†LLMé‡å¤å®ç°...")
    
    # æ£€æŸ¥llm.pyå’Œllm_manager.py
    llm_simple = "src/owl_requirements/services/llm.py"
    llm_manager = "src/owl_requirements/services/llm_manager.py"
    
    if os.path.exists(llm_simple) and os.path.exists(llm_manager):
        print(f"  ğŸ” å‘ç°ä¸¤ä¸ªLLMå®ç°:")
        print(f"    - {llm_simple} (ç®€å•å®ç°)")
        print(f"    - {llm_manager} (å®Œæ•´å®ç°)")
        
        # æ£€æŸ¥å“ªä¸ªè¢«æ›´å¤šä½¿ç”¨
        simple_usage = 0
        manager_usage = 0
        
        for root, dirs, files in os.walk("src"):
            dirs[:] = [d for d in dirs if d != "__pycache__"]
            for file in files:
                if file.endswith('.py'):
                    filepath = os.path.join(root, file)
                    try:
                        with open(filepath, 'r', encoding='utf-8') as f:
                            content = f.read()
                            if 'from ..services.llm import' in content or 'from .llm import' in content:
                                simple_usage += 1
                            if 'from ..services.llm_manager import' in content or 'from .llm_manager import' in content:
                                manager_usage += 1
                    except Exception:
                        continue
        
        print(f"    ğŸ“Š ä½¿ç”¨ç»Ÿè®¡:")
        print(f"      - llm.py: {simple_usage} æ¬¡å¼•ç”¨")
        print(f"      - llm_manager.py: {manager_usage} æ¬¡å¼•ç”¨")
        
        if manager_usage > simple_usage:
            print(f"    ğŸ—‘ï¸ åˆ é™¤è¾ƒå°‘ä½¿ç”¨çš„ llm.py")
            try:
                os.remove(llm_simple)
                print(f"    âœ… å·²åˆ é™¤: {llm_simple}")
            except Exception as e:
                print(f"    âš ï¸ åˆ é™¤å¤±è´¥: {e}")
        else:
            print(f"    âœ… ä¿ç•™ä¸¤ä¸ªå®ç°ï¼Œllm_manager.pyä½¿ç”¨æ›´å¹¿æ³›")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç³»ç»Ÿæ¸…ç†...")
    print("=" * 60)
    
    # 1. æŸ¥æ‰¾å¹¶æŠ¥å‘Šé‡å¤æ–‡ä»¶
    duplicates = find_duplicate_files()
    if duplicates:
        print(f"ğŸ” å‘ç° {len(duplicates)} ç»„é‡å¤æ–‡ä»¶:")
        for i, (content_hash, files) in enumerate(duplicates.items()):
            print(f"  ç»„ {i+1}: {len(files)} ä¸ªæ–‡ä»¶")
            for file in files:
                print(f"    - {file}")
    
    # 2. æŸ¥æ‰¾ç›¸ä¼¼æ–‡ä»¶
    similar = find_similar_files()
    if similar:
        print(f"\nğŸ” å‘ç° {len(similar)} å¯¹ç›¸ä¼¼æ–‡ä»¶:")
        for file1, file2, similarity in similar:
            print(f"  ç›¸ä¼¼åº¦ {similarity:.2%}: {file1} <-> {file2}")
    
    # 3. åˆ†æLLMå®ç°
    llm_files = analyze_llm_implementations()
    
    # 4. æ¸…ç†é‡å¤æ¨¡æ¿
    cleanup_duplicate_templates()
    
    # 5. æ¸…ç†é‡å¤çš„Webæ¨¡æ¿
    cleanup_web_templates()
    
    # 6. æ¸…ç†LLMé‡å¤å®ç°
    cleanup_llm_duplicates()
    
    # 7. æ¸…ç†ç©ºç›®å½•
    cleanup_empty_dirs()
    
    # 8. éªŒè¯æ¨¡æ¿ä¸€è‡´æ€§
    verify_template_consistency()
    
    # 9. åˆ›å»ºA2Aé€šä¿¡æ¡†æ¶
    create_a2a_framework()
    
    print("\n" + "=" * 60)
    print("âœ… ç³»ç»Ÿæ¸…ç†å®Œæˆï¼")
    
    print("\nğŸ“Š æ¸…ç†æ€»ç»“:")
    print("- ç»Ÿä¸€äº†æ¨¡æ¿å­˜å‚¨ä½ç½®åˆ° templates/prompts/")
    print("- åˆ é™¤äº†é‡å¤çš„æ¨¡æ¿æ–‡ä»¶")
    print("- æ¸…ç†äº†é‡å¤çš„Webæ¨¡æ¿")
    print("- åˆ†æäº†LLMå®ç°é‡å¤æƒ…å†µ")
    print("- æ¸…ç†äº†ç©ºç›®å½•")
    print("- éªŒè¯äº†æ¨¡æ¿ä¸€è‡´æ€§")
    print("- åˆ›å»ºäº†A2Aé€šä¿¡æ¡†æ¶")

if __name__ == "__main__":
    main()
